---
author: "pgaleone"
layout: "post"
title:  "3D-BoNet analysis and TensorFlow 2 implementation"
slug:   "3D-BoNet analysis and TensorFlow 2 implementation"
date:    2021-04-20 8:00:00
categories: machine-learning
image: images/3dbonet/3d-bonet-architecture.png
tags: machine-learning
---

Instance segmentation on point clouds is a challenging problem: point clouds are unordered, sparse, non-uniform and finding non regulars shapes is not trivial. The 3D-BoNet architecture [1] has been recently introduced to tackle the problem: this networks is trainable end-to-end, and it contains an useful bounding box prediction network that's used to improve the instance segmentation results. The article contains a walkthrough the paper, section by section, and at the end introduces the steps we followed to convert the original implementation (in TensorFlow 1) to our own implementation in TensorFlow 2.

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="point mask prediction branch" src="/images/3dbonet/instance-header.png">
        <figcaption>A sample extracted from the paper [1]. On the left the input point cloud, center the instance segmentation result with 3D-BoNet, right the ground truth.</figcaption>
    </figure>
</div>

## Introduction

Instance segmentation on point clouds is difficult, because the point clouds are inherently unordered, unstructured and non-uniform. The traditional CNNs require a voxelization of the 3D point clouds, that is computational and memory intensive.

There are architectures that do not look at the voxels, but look directly at the points like SGPN, ASIS, JSIS3D, MASC, 3D-BEVIS, but all these methods do not explicitly detect object boundaries (the bounding boxes) and all of them require post-processing, like mean-shift clustering, which is computationally intensive.

3D-BoNet wants to overcome the precedent approaches: MLPs -> detect instances -> accurate segmentation through a point-level binary classifier. For doing this, they introduced a **bounding box prediction module** and a series of carefully designed loss functions to directly learn object boundaries.

NOTE: no post process and no object proposal are used.

## The Bounding Box prediction branch

Goal: predict a unique, unoriented, rectangular bounding box for each instance, in a single forward space without relying on predefined spatial anchors or RPN (Region Proposal Network).

Problems:

1. The number of total instances is variable (1 to many)
2. There is no fixed order for all instances.

How to directly link predicted bounding boxes with ground trough labels to supervise the network?

The BBPB simply takes the global feature vector as input and directly output a **large and fixed number of bounding boxes together with confidence scores**.

To supervise the network, the authors introduced a **bounding box association layer** followed by a multi-criteria loss function.

**Given a set of ground-truth instances, we need to determine which of the predicted boxes best fit them.** -> This can be formulated as an optimal assignment problem and solved using an existing solver.

After the association of the bboxes with the gt-boxes, the multi-criteria loss minimized the distance between the paired box and also maximizes the coverage of valid points inside of predicted boxes.

## Point Mask prediction branch

The predicted boxes and the global features extracted by the backbone, are then fed into the point mask prediction branch to predict a point-level binary mask for each instance.

Goal: classify whether each point inside of a bbox belongs to the valid instance or the background.

## Detailed architecture

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="detailed architecture" src="/images/3dbonet/3d-bonet-architecture.png">
        <figcaption>The 3D Bo-Net architecture</figcaption>
    </figure>
</div>

The architecture is very similar to a traditional architecture used on images: backbone (feature extractor) and different heads for doing multi-taks learning. Each head has a specific goal.

Given an input point cloud $$\textbf{P}$$ with $$N$$ points in total $$\textbf{P} \in \mathbb{R}^{N \times k_0} $$ where $$ k_0 $$ is the number of channels such as the location $$\{x,y,z\}$$ and color $$\{r,g,b\}$$ of each point, the backbone network extract **point local features** $$\textbf{F}_l \in \mathbb{R}^{N \times k}$$, and aggregates a **global point cloud feature vector** $$\textbf{F}_g \in \mathbb{R}^{1 \times k}$$, where $$k$$ is the lenght of feature vectors.

The bounding box prediction branch takes $$\textbf{F}_g$$ as input and regress a **predefined and fixed set of bounding boxes** $$B$$ and the corresponding box scores $$B_s$$.

During the training this branch is supervised with ground truth bounding bboxes and fed into a **box association layer** that automatically associates a unique and most similar predicted bounding box to each ground truth box.

The output of the association layer is a list of association index $$\textbf{A}$$.

Using the indices, the predicted bboxes are reorganized such that each gt box is paired with only one predicted box for the loss calculation. The predicted boxes are also reordered accordingly (the score) before the loss calculation.

**note**: the bounding box association layer and multi-criteria loss function are only designed for network training - discarded, thus, during testing.

Every predicted box + the local and global features ($$\textbf{F}_l$$ and $$\textbf{F}_g$$) are fed into the **point mask prediction branch** -> this branch is shared by all instances of difference categories, and therefore extremely light and compact. This is a **class agnostic** approach that allows general segmentation across **unseen categories**.


### Bounding Box Prediction

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="bbox prediction" src="/images/3dbonet/3d-bo-net-bbox.png">
    <figcaption> The Bounding box predictiond module </figcaption>
    </figure>
</div>

Simple parametrization of bbox: $$ \{ [x_\text{min}, y_\text{min}, z_\text{min}], [x_\text{max}, y_\text{max}, z_\text{max}]\} $$

#### Neural architecture

The global feature vector $$\textbf{F}_g$$ is fed through 2 fully connected layers with Leaky ReLU, followed by 2 parallel FC layers.

- 1 layer outputs a 6H dimensional vector, reshaped into a $$ H \times 2 \times 3$$ tensor, where H is the **predefined and fixes number of bounding boxes**
- 1 layer outputs a H dimensional vector followed by a **sigmoid** to represent the bounding box scores.


**Bounding Box Association Layer**

Given the H predicted bboxes $$ \textbf{B} \in \mathbb{R}^{H \times 2 \times 3} $$ how to use the gt bboxes $\textbf{\bar{B}} \in \mathbb{R}^{T \times 2 \times 3}$$ to supervise the network?

For every input point cloud, the number of gt boxes T varies  and it's different from H - very often T < H. Moreover, there's no box order for either predicted or gt boxes.

**Optimal Association Formulation**

Let $$\textbf{A}$$ be a boolean association matrix where $$\textbf{A}_{i,j} = 1 \iff \text{the} \quad i^{\text{th}}$$ predicted bbox is assigned to the $$j^{\text{th}}$$ gt box.

$$\textbf{A}$$ = the association index.

Let $$\textbf{C}$$ be the association **cost matrix** where $$\textbf{C}_{i,j}$$ represents the cost that the $$i^{th}$$ predicted box is assigned to the $$j^{\text{th}}$$ gt box.

The less the cost, the more similar are 2 boxes. Hence, the box association problem is to find the optimal assignment matrix $$	extbf{A} with the **minimal cost overall**:

$$ A = \text{argmin}_{A} \sum_{i=1}^{H}{\sum_{j=1}^{T}{C_{i,j}A_{i,j}}} $$ subject to $$ \sum_{i=1}^{H}{A_{i,j}} = 1, \sum_{j=1}^{T}{A_{i,j}} \le 1, j \in {1..T}, i \in {1..H} $$

To solve the above optimal association problem, the existing **Hungarian algorithm** is applied.

#### Association Matrix Calculation

To evaluate the similarity between the $$i^\text{th}$$ predicted bbox and the $$j^\text{th}$$ gt box, the Euclidean distance between 2 pairs of min-max vertices is not enough, because we need the predicted bbox to contain as many valid points as possible since the points clouds are usually sparse and distributed non-uniformly in 3D space.

Therefore, also the **coverage** of valid points should be included the calculate the cost matrix C. The final association cost is the sum of 3 costs.

1. **Euclidean Distance between Vertices**. $$ C^{ed}_{i,j} = \frac{1}{6}\sum{(B_i - \bar{B}_j)^2} $$
2. **Soft IoU on Points**. For every point of the point cloud, we need to know if it falls inside a  predicted bbox or not.
    It's possible to obtain a **hard-binary vector** $$\bar{q}_j \in R^N$$ to represents whether each point is inside of the box or not, where every $$\bar{q}_i%$$ is 1 or 0.

    But we also need a differentiable value (wrt predicted boxes) that associates to every point of the point cloud a probability value, that this point is inside a predicted bounding box.

    The vector $$q$$ is called **point-in-pred-box-probability** and it's obtained applying the following algorithm.

    **Algorithm for calculating point-in-pred-box probability**

    Given
    - H, the number of predicted boxes B
    - N, the number of points in the point cloud P
    - $$\theta_1$$ and $$\theta_2$$ hyperparameters (value 100 and 20 respectively).

    <div class="blog-image-container">
        <figure>
            <img class="blog-image" alt="Algorithm" src="/images/3dbonet/algorithm1.png" style="width:50%">
            <figcaption>The algorithm for calculating point-in-pred-box probability</figcaption>
        </figure>
    </div>

    The deeper the corresponding point is inside of the box, the higher the value.

    The SIoU (Soft IoU) cost between the $$i^\text{th}$$ predicted box and the $$j^\text{th}$$ gt box is defined as

    $$ C_{i,j}^{\text{sIoU}} = \frac{-\sum{n=1}^N{(q_i^n \cdot \bar{q}^n_j)}}{\sum_{n=1}^N{q_i^n}+\sum_{n=1}^{N}{\bar{q}^n_n} - \sum_{n=1}^N{(q_i^n \cdot \bar{q}_j^n)}} $$

    where $$q^n_i$$ and $$\bar{q}^n_j$$ are the $$n^\text{th}$$ values of $$q_i$$ and $$\bar{q}_j$$.

3. **Cross-Entropy Score**. It's useful to consider also the cross-entropy score between $$q_i$$ and $$\bar{q}_j$$. Being different from the sIoU cost with prefers tighter boxes, this score represents how **confident** a predicted bounding box is able to include valid points as many as possible. This score prefers larger and more inclusive boxes (this means that it counter balances the sIoU) and it's formally defined as:

$$ C^\text{ces}_{i,j} = - \frac{1}{N}\sum_{n=1}^N{[\bar{q}_j^n \log q_i^n + (1 - \bar{q}_j^n)\log(1-q_i^n)]} $$


The final association cost between the $$i^\text{th}$$ and the $$j^\text{th}$$ gt box is defined as:

$$ C_{i,j} = C^{ed}_{i,j} + C^{\text{sIoU}}_{i,j} + C^{\text{ces}}_{i,j} $$

Where the Euclidean criterion guarantees the geometric boundaries, and the sIoU and the ces criteria maximize the coverage of valid points and overcome the non uniformity.


#### Loss Functions

NOTE: after the bbox association layer, both predicted boxes and scores are reordered using the association index A, such that the first predicted boxes and the scores are wall paired with the T gt boxes.

**Multi-criteria Loss for Box prediction**.  We want to minimize the association cost previously defined, e.g.

$$ \mathcal{l_\text{bbox}} = \frac{1}{T} \sum_{t=1}^{T}{C^{ed}_{t,t} + C^{\text{sIoU}}_{t,t} + C^{\text{ces}}_{t,t}} $$

where all the terms are the costs of the $$t^\text{th}$$ paired boxes. NOTE: we only minimize the cost of T paired boxes, the remaining H- T are ignored.

**Loss for Box Score Prediction**. The predicted box scores aim to indicate the validity of the corresponding predicted boxes. After being reordered, the GT scores for the first T scores are all 1 and 0 for all the remaining H-T scores. We can thus use the cross entropy loss for this binary classification task:


$$ \mathcal{l_\text{bbs}} = -\frac{1}{H} \left[ \sum_{t=1}^{T}{B^t_s} + \sum_{t=T+1}^{H}{\log(1- B^t_s)} \right] $$

where $$B_s^t$$ is the $$t^\text{th}$$ predicted score after being associated. This loss rewards correctly predicted bounding boxes and implicitly penalizes the cases where multiple similar boxes are regressed for a single instance.

### Point mask prediction branch

<div class="blog-image-container">
    <figure>
        <img class="blog-image" alt="point mask prediction branch" src="/images/3dbonet/3d-pointmask-prediction.png">
        <figcaption>Point mask prediction branch architecture</figcaption>
    </figure>
</div>

Given the predicted boxes B, the learn point features $$F_l$$ and the global features $$F_g$$, the point mask prediction branch processes each bbox individually with shared neural layers.

**Neural layers**: The point and global features are compressed to a 256-dimensional vector trough FC layers, before being concatenated and compressed to a 128-dimensional mixed point feature $$\tilde{F}_l$$.

For the $$i^\text{th}$$ predicted bbox $$B_i$$ the estimated vertices and score are fused with features $$\tilde{F}_l$$ through concatenation, producing a **box-aware features** $$\hat{F}_l$$. These features are then fed through shared layers, predicting a point level binary mask, denoted as $$M_i$$. Sigmoid is then applied as last activation function.

**Loss function**

The predicted instance masks M are similarly associated with the gt masks according to the association index A. Due to imbalance of instance and background point they use **focal loss** with default hyper-parameters instead of the standard cross-entropy. Only the valid T paired masks are used for the loss $$\mathcal{l_\text{pmask}}$$.

## End-to-End implementation & semantic segmentation loss

Backbone of choice: PointNet++.

For semantic segmentation, pointwise softmax cross-entropy loss function is used $$\mathcal{l_\text{sem}}$$. Given an input point cloud P, all the branches are linked and end-to-end trained using a single combined multi-task loss:

$$ \mathcal{l_\text{all}} = \mathcal{l_\text{sem}} + \mathcal{l_\text{bbox}} + \mathcal{l_\text{bbs}} + \mathcal{l_\text{pmask}} $$


Optimizer Adam. lr: 5e-4, divided by 2 every 20 epochs.

---

[1] [Learning Object Bounding Boxes for 3D Instance Segmentation on Point Clouds](https://arxiv.org/abs/1906.01140)
